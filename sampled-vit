import torch
import torch.nn as nn
import torch.nn.functional as F
from einops import rearrange


class LightScoringNet(nn.Module):
        """轻量化评分网络（通道+空间注意力结合）"""

        def __init__(self, in_channels, reduction_ratio=8):
                super().__init__()
                self.channel_att = nn.Sequential(
                        nn.AdaptiveAvgPool2d(1),
                        nn.Conv2d(in_channels, in_channels // reduction_ratio, 1),
                        nn.ReLU(),
                        nn.Conv2d(in_channels // reduction_ratio, in_channels, 1),
                        nn.Sigmoid()
                )
                self.spatial_att = nn.Conv2d(in_channels, 1, 1)  # 1x1卷积输出空间得分

        def forward(self, x):
                c_att = self.channel_att(x)  # [B, C, 1, 1]
                s_att = self.spatial_att(x)  # [B, 1, H, W]
                return c_att * s_att  # 融合得分 [B, 1, H, W]


class DynamicOmega(nn.Module):
        """动态ω生成模块（基于特征统计）"""

        def __init__(self, min_omega=0.3, max_omega=0.7):
                super().__init__()
                self.min_omega = min_omega
                self.max_omega = max_omega
                self.mlp = nn.Sequential(
                        nn.Linear(1, 16),
                        nn.ReLU(),
                        nn.Linear(16, 1),
                        nn.Sigmoid()  # 输出范围[0,1]
                )

        def forward(self, scores):
                # scores: [B, 1, H, W]
                mu = torch.mean(scores, dim=(1, 2, 3), keepdim=True)  # 均值 [B,1,1,1]
                omega = self.mlp(mu.flatten(1))  # [B,1]
                omega = self.min_omega + (self.max_omega - self.min_omega) * omega
                return omega  # [B,1]


class SampledViT(nn.Module):
        def __init__(self, in_channels=3, patch_size=16, dim=128, num_heads=4):
                super().__init__()
                # 骨干网络 (EfficientNetB5简化版)
                self.backbone = nn.Sequential(
                        nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3),
                        nn.ReLU(),
                        nn.MaxPool2d(kernel_size=3, stride=2, padding=1),
                        *[ResBlock(64) for _ in range(3)]
                )

                # 评分与采样
                self.scoring_net = LightScoringNet(64)
                self.omega_generator = DynamicOmega()

                # Transformer部分
                self.patch_embed = nn.Conv2d(64, dim, kernel_size=patch_size, stride=patch_size)
                self.pos_embed = nn.Parameter(torch.randn(1, dim, 16, 16))
                self.transformer_encoder = nn.TransformerEncoder(
                        nn.TransformerEncoderLayer(d_model=dim, nhead=num_heads),
                        num_layers=6
                )

                # 分割头
                self.decoder = nn.Sequential(
                        nn.Conv2d(dim, 64, 3, padding=1),
                        nn.Upsample(scale_factor=4, mode='bilinear'),
                        nn.Conv2d(64, 1, 1)
                )

        def forward(self, x):
                # 1. 特征提取
                features = self.backbone(x)  # [B,64,H/4,W/4]

                # 2. 动态采样
                scores = self.scoring_net(features)  # [B,1,H/4,W/4]
                omega = self.omega_generator(scores)  # [B,1]

                # 3. Top-N采样 (N = ω*L)
                B, _, H, W = scores.shape
                L = H * W
                N = int(omega.mean().item() * L)  # 实际实现需按batch处理

                # 展平并取Top-N特征
                scores_flat = rearrange(scores, 'b 1 h w -> b (h w)')  # [B,L]
                _, top_idx = torch.topk(scores_flat, k=N, dim=1)  # [B,N]

                # 4. Transformer处理
                patches = self.patch_embed(features)  # [B,dim,h,w]
                patches = rearrange(patches, 'b c h w -> b (h w) c')
                patches = patches + self.pos_embed

                # 仅保留Top-N特征
                sampled_patches = torch.gather(patches, 1, top_idx.unsqueeze(-1).expand(-1, -1, dim))
                encoded = self.transformer_encoder(sampled_patches)

                # 5. 解码分割图
                output = self.decoder(encoded)
                return output


class ResBlock(nn.Module):
        """简化版ResBlock"""

        def __init__(self, channels):
                super().__init__()
                self.conv = nn.Sequential(
                        nn.Conv2d(channels, channels, 3, padding=1),
                        nn.BatchNorm2d(channels),
                        nn.ReLU(),
                        nn.Conv2d(channels, channels, 3, padding=1),
                        nn.BatchNorm2d(channels)
                )

        def forward(self, x):
                return F.relu(x + self.conv(x))
